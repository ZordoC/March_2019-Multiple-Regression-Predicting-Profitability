library(caret)
library(readr)
library(rstudioapi)
library(e1071)
library(dplyr)
library(rpart)
library(reshape)
library(corrplot)
#For cleaning variables
#rm(list = setdiff(ls(), lsf.str()))

current_path = getActiveDocumentContext()$path
setwd(dirname(current_path))
setwd("..")
rm(current_path)
EP <- read.csv( file ="./data/Epa.csv" , header = TRUE , sep = ',')
NP <- read.csv(file = "./data/Npa.csv", header = TRUE , sep =',')


#### Pre Processing ####
EP <- EP[,c(1,5,9,18)]
EP <- PPfunction(EP)
EP <- RmOut(EP,Volume)
# 
# EP
# corr_all <- cor(EP)
# corr_all
# 
# corrplot(corr_all,type="upper",tl.pos="td",method="circle",tl.cex = 0.5,tl.col='black',diag=FALSE)

#### Training and Testing sets ####

List <- TrainAndTestSets(EP$Volume,0.75,EP,123)

#### Random Forest ####
ModelRandomForest <- TrainingFunction("rf",Volume~ x4StarReviews,List$trainingSet)

# Mrandom <- train(Volume ~ x4StarReviews, data = List$trainingSet, method = "rf",trainControl=trainControl(method = "repeatedcv", repeats = 4))

PredictionRandomForest <- predict(ModelRandomForest,List$testingSet)

TestResultsRF <- postResample(PredictionRandomForest,List$testingSet$Volume)

 
TestResultsRF


#### SVM ####

svm.model <- TrainingFunction("svm",Volume~.,List$trainingSet,100000,0.00001)  

svm.pred <- predict(svm.model,List$testingSet)

TestResultsSVM <- postResample(svm.pred,List$testingSet$Volume)



TestResultsSVM

#### knn ####

 
 KNN <- TrainingFunction("knn",Volume~.,List$trainingSet)
 
# KnnList <- TrainAndTestSets(EP$Volume,0.75,EP,233)




KnnPrediction <- predict(KNN,List$testingSet)

TestResultsKNN <-postResample(KnnPrediction,List$testingSet$Volume)

TestResultsKNN
####


AllTestResults <- cbind(TestResultsKNN,TestResultsRF,TestResultsSVM)

AllTestResults              



#### Training All 3 models at once #### 


#TrainAll3Models(Volume ~.,List$trainingSet)

#### Errors ####

ABSrf <- List$testingSet$Volume - PredictionRandomForest 

RLTrf <- ABSrf / List$testingSet$Volume 



ABsKnn <- List$testingSet$Volume - KnnPrediction 

RLTknn <- ABsKnn / List$testingSet$Volume 



ABSsvm <-  List$testingSet$Volume - svm.pred

RLTsvm <-  ABSsvm / List$testingSet$Volume 

ABSrf <- as.data.frame(ABSrf)

ABSsvm <- as.data.frame(ABSsvm)

plot(ABSsvm)

ABsKnn <-as.data.frame(ABsKnn)

RealAndPrediction <- cbind(List$testingSet$Volume,ABsKnn)  

RealAndPrediction

ErrorPlotKnn <- ggplot(data = RealAndPrediction , aes(x = Abs,y=RealAndPrediction$ABsKnn$Volume) ) + geom_point()

ErrorPlotKnn


list_3_models <- TrainAll3Models(Volume ~ x4StarReviews + PositiveServiceReview,EP)


##### Best approach ( mentors)


a <- c("Volume ~ x4StarReviews","Volume ~.","Volume ~ PositiveServiceReview")
b <- c("rf", "knn")
compare_var_mod <- c()

for ( i   in a) {
  for (j in b) {
    
    model <- train(formula(i), data = List$trainingSet, method = b,trainControl=trainControl(method = "repeatedcv", repeats = 4))
    
    pred <- predict(model, newdata = List$testingSet)
    
    pred_metric <- postResample(List$testingSet$Volume, pred)
    
    compare_var_mod <- cbind(compare_var_mod , pred_metric)
    
  }
  
}
      compare_var_mod

names_var <- c()
for (i in a) {
  for(j in b) {
    names_var <- append(names_var,paste(i,j))
  }
}


names_var


colnames(compare_var_mod) <- names_var

compare_var_mod


compare_var_mod_melt <- melt(compare_var_mod, varnames = c("metric", "model"))
compare_var_mod_melt <- as.data.frame(compare_var_mod_melt)
compare_var_mod_melt



ggplot(compare_var_mod_melt, aes(x=model,y=value)) + geom_col() + facet_grid(metric~., scales="free")



# Efunction <- function (data,seed)
#   {
#   
#   prediction <- vector(mode = "list", length = 3)
#   abs <- vector(mode="list", length=3)
#   rlt <- vector(mode="list", length=3)
#         List <- TrainAndTestSets(data$Volume,0.75,data,123)
#         #List <- TrainAndTestSets(EP$Volume,0.75,EP,233)
#    Model <- TrainAll3Models(Volume~.,List$trainingSet)
#     RealValue <-  List$testingSet$Volume
#                 for(i in 1:length(Model)){
#       
#                   
#                   
#               prediction[[i]] <- predict(Model[i],List$testingSet) 
#                     
#         
#                   abs[[i]] <- abs(prediction[[i]] - List$testingSet$Volume)
#                  # rlt[[i]] <- abs[i]/ List$testingSet$Volume[i]
#               
#                 }
#                 
#    list(AbsoluteE=abs,RelativeE = rlt,predi=prediction)
#    
# }


# 
# 
# O234 <- Efunction(EP,123)
# View(O234)  
#   
# summary(Model[2])
# 
# Model1 <- Models[[1]]
# 
# Model1
# 
# prediction <- predict(Models[[1]],List$testingSet)  
# 
# summary(Models[2])
# 
# postResample(prediction,List$testingSet$Volume)
# 
# 
# 




# a <- c("knn","rf")
# 
# compmodel <- c()
# for (i in a) {
#   
#   model <- train(Volume~.,
#                  EP,method= a,
#                  train = List$trainingSet,
#                  trainControl = trainControl(method = "repeatedcv", 
#                                              repeats = 4))
#   
#   pred <- predict(model,List$testingSet)
#   
#   metric <- postResample(pred,List$testingSet$Volume)
#   
#  
#   
#    compmodel <- cbind(metric,compmodel)
#    
# }
#   for (j in 1:2)
#     {
#     print(j)
#    
#     
#      colnames(compmodel)[j] <- a[j]
#   
#   
#     }
# compmodel

# 
# 
# a <- c("knn","rf")
# 
# 
# 
# 
# MyNewTable <- melt(compmodel,id=("Value"))
# 
# MyNewTable
#   ggplot(MyNewTable,aes(x=X1,y=X2)) + geom_col() + facet_grid(X1 ~.,scales="free")
#  
#   






